{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lentil import evaluate\n",
    "from lentil import models\n",
    "\n",
    "import mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import omem # https://github.com/rddy/leitnerq/blob/eb81f705dbcd5de701da1ad45db35cd934355889/nb/mem.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('text.latex', preamble='\\usepackage{amsfonts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'mnemosyne_history.pkl'), 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(r'Delay ($\\log_{10}$-seconds)')\n",
    "plt.ylabel('Frequency (Number of Interactions)')\n",
    "plt.hist(np.log10(1 + (history.data['timestamp'] - history.data['tlast']).values), bins=20)\n",
    "plt.savefig(os.path.join('figures', 'mnemosyne_mindelay', 'delay-hist.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_delays = np.exp(np.arange(0, 16, 16 / 10))\n",
    "len(min_delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history.data.sort('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deck_of_student_item = [{} for _ in min_delays]\n",
    "\n",
    "deck = [[] for _ in min_delays]\n",
    "for _, ixn in history.data.iterrows():\n",
    "    student_item = (ixn['user_id'], ixn['module_id'])\n",
    "    for i, min_delay in enumerate(min_delays):\n",
    "        d = deck_of_student_item[i].get(student_item, 1)\n",
    "        deck[i].append(d)\n",
    "    \n",
    "        if ixn['outcome']:\n",
    "            if ixn['timestamp'] - ixn['tlast'] >= min_delay:\n",
    "                deck_of_student_item[i][student_item] = d + 1\n",
    "            else:\n",
    "                deck_of_student_item[i][student_item] = d\n",
    "        else:\n",
    "            deck_of_student_item[i][student_item] = max(1, d-1)\n",
    "\n",
    "for i, x in enumerate(min_delays):\n",
    "    history.data['deck_%d' % x] = deck[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'mnemosyne_history_vMINDELAY.pkl'), 'wb') as f:\n",
    "    pickle.dump(history, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the IRT benchmark models and memory models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def meta_build_efc_model(\n",
    "    strength_model='deck', using_delay=True, \n",
    "    using_global_difficulty=True, debug_mode_on=True):\n",
    "    def build_efc_model(history, filtered_history, split_history=None):\n",
    "        model = omem.EFCModel(\n",
    "            filtered_history, strength_model=strength_model, using_delay=using_delay, \n",
    "            using_global_difficulty=using_global_difficulty, debug_mode_on=debug_mode_on)\n",
    "        model.fit(\n",
    "            #learning_rate=0.1, \n",
    "            learning_rate=(10000 if not using_global_difficulty else 0.1), \n",
    "            ftol=1e-6, max_iter=200)\n",
    "        return model\n",
    "    return build_efc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_builders = {}\n",
    "model_builders.update({('GMIND%d' % x): meta_build_efc_model(\n",
    "        strength_model=('deck_%d' % x), using_global_difficulty=True) for x in min_delays})\n",
    "model_builders.update({('IMIND%d' % x): meta_build_efc_model(\n",
    "        strength_model=('deck_%d' % x), using_global_difficulty=False) for x in min_delays})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Number of models = %d\" % (len(model_builders))\n",
    "print '\\n'.join(model_builders.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate.cross_validated_auc(\n",
    "    model_builders,\n",
    "    history,\n",
    "    num_folds=10,\n",
    "    random_truncations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump results to file\n",
    "with open(os.path.join('results', 'mnemosyne_mindelay.pkl'), 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load results from file, replacing current results\n",
    "with open(os.path.join('results', 'mnemosyne_mindelay.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stderr = lambda x: np.std(x) / np.sqrt(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Global Difficulty')\n",
    "plt.xlabel('Minimum Delay (Seconds)')\n",
    "plt.ylabel('AUC')\n",
    "plt.errorbar(\n",
    "    min_delays, [np.mean(results.validation_aucs('GMIND%d' % x)) for x in min_delays], \n",
    "    yerr=[stderr(results.validation_aucs('GMIND%d' % x)) for x in min_delays],\n",
    "    label='Validation')\n",
    "plt.scatter(\n",
    "    min_delays, [results.test_auc('GMIND%d' % x) for x in min_delays], \n",
    "    color='orange', linewidth=0, label='Test')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mnemosyne_mindelay', 'auc-vs-mindelay-global-difficulty.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title('Item-specific Difficulty')\n",
    "plt.xlabel('Minimum Delay (Seconds)')\n",
    "plt.ylabel('AUC')\n",
    "plt.errorbar(\n",
    "    min_delays, [np.mean(results.validation_aucs('GMIND%d' % x)) for x in min_delays], \n",
    "    yerr=[stderr(results.validation_aucs('GMIND%d' % x)) for x in min_delays],\n",
    "    label='Validation')\n",
    "plt.scatter(\n",
    "    min_delays, [results.test_auc('GMIND%d' % x) for x in min_delays], \n",
    "    color='orange', linewidth=0, label='Test')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mnemosyne_mindelay', 'auc-vs-mindelay-item-difficulty.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Minimum Delay (Seconds)')\n",
    "plt.ylabel('Validation AUC')\n",
    "plt.errorbar(\n",
    "    min_delays, [np.mean(results.validation_aucs('GMIND%d' % x)) for x in min_delays], \n",
    "    yerr=[stderr(results.validation_aucs('GMIND%d' % x)) for x in min_delays],\n",
    "    label='Global Difficulty')\n",
    "plt.errorbar(\n",
    "    min_delays, [np.mean(results.validation_aucs('IMIND%d' % x)) for x in min_delays], \n",
    "    yerr=[stderr(results.validation_aucs('IMIND%d' % x)) for x in min_delays],\n",
    "    label='Item-specific Difficulty')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mnemosyne_mindelay', 'auc-vs-mindelay-global-vs-item-difficulty.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
